{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRQHpHKtN87k",
        "outputId": "b2f97cb4-c1dc-41ab-d823-ed4cb87c8b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set:\n",
            "Features: (11454, 109)\n",
            "Target: (11454,)\n",
            "\n",
            "Testing set:\n",
            "Features: (4909, 109)\n",
            "Target: (4909,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "data = pd.read_csv(\"census_preprocessed_dataset.csv\")\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(\"income\", axis=1)\n",
        "y = data[\"income\"]\n",
        "\n",
        "# Split the dataset into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Optionally, you can save the split datasets to CSV files\n",
        "X_train.to_csv(\"census_train_features.csv\", index=False)\n",
        "X_test.to_csv(\"census_test_features.csv\", index=False)\n",
        "y_train.to_csv(\"census_train_target.csv\", index=False)\n",
        "y_test.to_csv(\"census_test_target.csv\", index=False)\n",
        "\n",
        "# Print the shapes of the resulting datasets\n",
        "print(\"Training set:\")\n",
        "print(\"Features:\", X_train.shape)\n",
        "print(\"Target:\", y_train.shape)\n",
        "print(\"\\nTesting set:\")\n",
        "print(\"Features:\", X_test.shape)\n",
        "print(\"Target:\", y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "data = pd.read_csv(\"census_preprocessed_dataset.csv\")\n",
        "\n",
        "# Drop rows with missing target values\n",
        "data = data.dropna(subset=[\"income\"])\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(\"income\", axis=1)\n",
        "y = data[\"income\"]\n",
        "\n",
        "# Split the dataset into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Impute missing values in features\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_train_imputed = imputer.fit_transform(X_train)\n",
        "X_test_imputed = imputer.transform(X_test)\n",
        "\n",
        "# Define a function to evaluate each model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC()\n",
        "}\n",
        "\n",
        "# Evaluate each model\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    if name == \"Random Forest\":  # Use a pipeline for RandomForestClassifier with imputation\n",
        "        model_pipeline = make_pipeline(imputer, model)\n",
        "        accuracy, precision, recall, f1 = evaluate_model(model_pipeline, X_train, X_test, y_train, y_test)\n",
        "    else:\n",
        "        accuracy, precision, recall, f1 = evaluate_model(model, X_train_imputed, X_test_imputed, y_train, y_test)\n",
        "    results[name] = {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    }\n",
        "\n",
        "# Print results\n",
        "print(\"\\nResults:\")\n",
        "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppIeVoDmOqMv",
        "outputId": "d3ae99e3-ff62-44aa-b742-f04c18c55eb4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Logistic Regression...\n",
            "Evaluating Random Forest...\n",
            "Evaluating Support Vector Machine...\n",
            "\n",
            "Results:\n",
            "                        Accuracy  Precision    Recall  F1 Score\n",
            "Logistic Regression     1.000000   1.000000  1.000000  1.000000\n",
            "Random Forest           1.000000   1.000000  1.000000  1.000000\n",
            "Support Vector Machine  0.990366   0.998316  0.961102  0.979356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "data = pd.read_csv(\"census_preprocessed_dataset.csv\")\n",
        "\n",
        "# Drop rows with missing target values\n",
        "data = data.dropna(subset=[\"income\"])\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(\"income\", axis=1)\n",
        "y = data[\"income\"]\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC()\n",
        "}\n",
        "\n",
        "# Define K-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate each model using cross-validation\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    if name == \"Random Forest\":  # Use a pipeline for RandomForestClassifier with imputation\n",
        "        model_pipeline = make_pipeline(imputer, model)\n",
        "        scores = cross_val_score(model_pipeline, X_imputed, y, cv=kf, scoring=\"accuracy\")\n",
        "    else:\n",
        "        scores = cross_val_score(model, X_imputed, y, cv=kf, scoring=\"accuracy\")\n",
        "    results[name] = {\n",
        "        \"Mean Accuracy\": scores.mean(),\n",
        "        \"Standard Deviation\": scores.std(),\n",
        "        \"Accuracy Scores\": scores\n",
        "    }\n",
        "\n",
        "# Print results summary\n",
        "print(\"\\nResults Summary:\")\n",
        "for name, result in results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"Mean Accuracy: {result['Mean Accuracy']:.4f}\")\n",
        "    print(f\"Standard Deviation: {result['Standard Deviation']:.4f}\")\n",
        "    print(\"Accuracy Scores:\", result[\"Accuracy Scores\"])\n"
      ],
      "metadata": {
        "id": "8XYbkENwXaSH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1df03a4-2441-4a5b-8d97-72fcefc2581b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Logistic Regression...\n",
            "Evaluating Random Forest...\n",
            "Evaluating Support Vector Machine...\n",
            "\n",
            "Results Summary:\n",
            "\n",
            "Logistic Regression:\n",
            "Mean Accuracy: 1.0000\n",
            "Standard Deviation: 0.0000\n",
            "Accuracy Scores: [1. 1. 1. 1. 1.]\n",
            "\n",
            "Random Forest:\n",
            "Mean Accuracy: 0.9999\n",
            "Standard Deviation: 0.0001\n",
            "Accuracy Scores: [0.99973918 1.         1.         1.         1.        ]\n",
            "\n",
            "Support Vector Machine:\n",
            "Mean Accuracy: 0.9888\n",
            "Standard Deviation: 0.0006\n",
            "Accuracy Scores: [0.98852374 0.98904538 0.98956431 0.98773806 0.98930342]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# Load the preprocessed dataset\n",
        "data = pd.read_csv(\"census_preprocessed_dataset.csv\")\n",
        "\n",
        "# Drop rows with missing target values\n",
        "data = data.dropna(subset=[\"income\"])\n",
        "\n",
        "# Separate features (X) and target variable (y)\n",
        "X = data.drop(\"income\", axis=1)\n",
        "y = data[\"income\"]\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy=\"mean\")\n",
        "X_imputed = imputer.fit_transform(X)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": SVC()\n",
        "}\n",
        "\n",
        "# Define K-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Define metrics to calculate\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "\n",
        "# Evaluate each model using cross-validation\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"Evaluating {name}...\")\n",
        "    if name == \"Random Forest\":  # Use a pipeline for RandomForestClassifier with imputation\n",
        "        model_pipeline = make_pipeline(imputer, model)\n",
        "        cv_results = cross_validate(model_pipeline, X_imputed, y, cv=kf, scoring=scoring)\n",
        "    else:\n",
        "        cv_results = cross_validate(model, X_imputed, y, cv=kf, scoring=scoring)\n",
        "    results[name] = {\n",
        "        \"Accuracy\": cv_results['test_accuracy'],\n",
        "        \"Precision\": cv_results['test_precision'],\n",
        "        \"Recall\": cv_results['test_recall'],\n",
        "        \"F1 Score\": cv_results['test_f1']\n",
        "    }\n",
        "\n",
        "# Print results summary\n",
        "print(\"\\nResults Summary:\")\n",
        "for name, result in results.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    for metric, values in result.items():\n",
        "        print(f\"{metric}: Mean={values.mean():.4f}, Std Dev={values.std():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fgoVeTdIi1l",
        "outputId": "9bc282bf-1e1b-41c7-e168-048480013b7b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Logistic Regression...\n",
            "Evaluating Random Forest...\n",
            "Evaluating Support Vector Machine...\n",
            "\n",
            "Results Summary:\n",
            "\n",
            "Logistic Regression:\n",
            "Accuracy: Mean=1.0000, Std Dev=0.0000\n",
            "Precision: Mean=1.0000, Std Dev=0.0000\n",
            "Recall: Mean=1.0000, Std Dev=0.0000\n",
            "F1 Score: Mean=1.0000, Std Dev=0.0000\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: Mean=1.0000, Std Dev=0.0000\n",
            "Precision: Mean=1.0000, Std Dev=0.0000\n",
            "Recall: Mean=1.0000, Std Dev=0.0000\n",
            "F1 Score: Mean=1.0000, Std Dev=0.0000\n",
            "\n",
            "Support Vector Machine:\n",
            "Accuracy: Mean=0.9958, Std Dev=0.0005\n",
            "Precision: Mean=0.9975, Std Dev=0.0004\n",
            "Recall: Mean=0.9940, Std Dev=0.0009\n",
            "F1 Score: Mean=0.9958, Std Dev=0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1W7F9GZJOKjX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}